# Spore

Agentic AI framework with Lua scripting—spun out from [Moss](/projects/moss).

**Repository:** [github.com/rhizome-lab/spore](https://github.com/rhizome-lab/spore)

## Overview

Spore provides infrastructure for building AI coding agents:

- **Multi-provider LLM client** - Anthropic, OpenAI, Gemini, and 10 more via rig-core
- **Memory store** - SQLite-backed persistent context with metadata queries
- **Agent scripts** - Lua-based state machine with planner/explorer/evaluator roles

## Philosophy

**Spore** = agency/execution (LLM calls, memory, running agents)
**Moss** = intelligence (code analysis, session parsing, understanding)

The projects are intentionally not hard-linked. Moss can optionally extend Spore via a plugin architecture (dynamic library adding commands to Spore's Lua runtime).

## Crates

| Crate | Description |
|-------|-------------|
| `spore-core` | LLM client and memory store infrastructure |

## LLM Providers

Spore supports 13 LLM providers via rig-core:

- Anthropic, OpenAI, Azure, Gemini, Cohere, DeepSeek
- Groq, Mistral, Ollama, OpenRouter, Perplexity, Together, XAI

## Agent Architecture

The Lua agent scripts implement a state machine:

```
planner → explorer → evaluator (cycle)
```

Features:
- Shadow worktree mode for safe editing
- Checkpoint/resume for interrupted sessions
- Loop detection and max-turn safeguards
- Risk assessment for proposed changes

## Usage

```rust
use spore_core::{LlmClient, MemoryStore};

// Create LLM client
let client = LlmClient::new("anthropic", Some("claude-sonnet-4-5"))?;
let response = client.complete("Explain this code...", 1000).await?;

// Persistent memory
let memory = MemoryStore::open(&project_root)?;
memory.store("context", Some("agent"), 1.0, json!({}))?;
```

## Links

- [GitHub](https://github.com/rhizome-lab/spore)
- [Documentation](https://rhizome-lab.github.io/spore/)
